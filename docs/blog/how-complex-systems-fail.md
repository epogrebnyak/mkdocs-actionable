# Ричард Кук: "Как сбоят сложные системы"

В видео ниже Ричард Кук рассказывает про опыт работы с отказоустойчивыми, критическими системами в сфере медицины.

<iframe width="560" height="315" src="https://www.youtube.com/embed/2S0k12uZR14" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe> 

Ричард Кук также написал 18 тезисов о надежности информационных систем, 
многие их которых можно брать на знамена борьбы за отказоустойчивость.


Полностью тезисы есть на сайте <https://how.complexsystems.fail/>, здесь мы приводим 
заголовки наиболее ярких из них.

- Сложные системы содержат целые группы скрытых сбоев.
- Безопасность это характеристика системы, а не ее компонент.
- Решения, принимаемые при эксплуатации системы, всегда содержат элемент риска 
- Чтобы обеспечить работу без сбоев, нужен опыт работы со сбоями.

<!--  Переводы можно сюда:

1. Complex systems are intrinsically hazardous systems.
1. Complex systems are heavily and successfully defended against failure
1. Catastrophe requires multiple failures – single point failures are not enough.
1. Complex systems contain changing mixtures of failures latent within them.
1. Complex systems run in degraded mode.
1. Catastrophe is always just around the corner.
1. Post-accident attribution to a 'root cause' is fundamentally wrong.
1. Hindsight biases post-accident assessments of human performance.
1. Human operators have dual roles: as producers and as defenders against failure.
1. All practitioner actions are gambles.
1. Actions at the sharp end resolve all ambiguity.
1. Human practitioners are the adaptable element of complex systems.
1. Human expertise in complex systems is constantly changing
1. Change introduces new forms of failure.
1. Views of ‘cause’ limit the effectiveness of defenses against future events.
1. Safety is a characteristic of systems and not of their components
1. People continuously create safety.
1. Failure free operations require experience with failure.


- Сложные системы по своей сути уже являются уязвимыми.
- Сложные системы изначально имеют несколько уровней защиты от сбоев.
- Катастрофа является следствием множественных сбоев, а не единоразового инцидента.
- Сложные системы содержат целые динамичные группы скрытых в них сбоев.
- Сложные системы работают в деградированном режиме, они функционируют несмотря на наличие множества недостатков.
- Катастрофа всегда не за горами.
- Поскольку отказ системы всегда является причиной нескольких факторов, попытка установить "основную первопричину" сбоя обречена на провал.
- В ретроспективе мы не можем объективно оценить действия оператора, так как кажется, что оператор "должен был знать", что определеные факторы "неизбежно" приведут к свершившемуся сбою.
- Операторы систем играют двойную роль: как управляющие и как защитники от сбоев.
- Все действия оператора содержат в себе элемент риска.
- Оперативные решения оператора являются следствием целого ряда производственных факторов.
- Оператор являются адаптируемым элементом сложных систем.
- Опыт и навыки операторов в сложных системах постоянно меняются.
- Изменения в системах вводят новые формы сбоев.
- Ретроспектива «причин» ограничивает эффективность защиты от будущих сбоев.
- Безопасность - это характеристика системы, а не ee компонент.
- Безотказная работа - это результат действий людей, которые работают над тем, чтобы система оставалась в пределах допустимой производительности.
- Чтобы обеспечить работу без сбоев, нужен опыт работы со сбоями.

Перевод: https://github.com/epogrebnyak/mkdocs-actionable/issues/4#issuecomment-683755678

-->
